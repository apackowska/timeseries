---
title: "Efficient Market Hypothesis (Group assignment)"
self-contained: true
self-contained-math: true
format: html
editor: source
params:
  solutions: false
  print_sol: false
toc: true
toc-location: left
toc-depth: 6
---

```{r}
library(fpp3)
library(patchwork)
library(ggplot2)
```

# References

[1] Fama, Eugene (1970). "Efficient Capital Markets: A Review of Theory and Empirical Work". Journal of Finance. 25 (2): 383–417. doi:10.2307/2325486. JSTOR 2325486.

[2] Investopedia - Efficient Market Hypothesis [Link](https://www.investopedia.com/terms/e/efficientmarkethypothesis.asp)

# The Efficient Market Hypothesis

The goal of this assignment is to compare a prediction strategy based on the Efficiet Market Hypothesis (EMH) with some of the first non-trivial models you have learnt: simple exponential smoothing and trended exponential smoothing (additive and additive damped versions).

Essentially, the EMH states that stocks are accurately priced and reflect all available information. If it holds true, it implies that it impossible to consistently beat the market by analysis.

In his influential 1970 paper ([1]), Eugene Fama proposes three categories of efficiency that differ in the information considered reflected in the prices:

1. *Weak-form of the EMH*: considers information contained in historical prices.
2. *Semi-strong form of EMH*: considers information publicly available beyond historical prices.
3. *Strong-form*: considers private (privileged) information.

Here we are going to consider the weak-form of the EMH and work only with the information contained in historical prices.

# Assignment

The assignment consists in:

### **1. Load the historical data and create an index associated to the training day** (0 points)

**Your final dataset must be an object of type `tsibble` with the following characteristics**:

* key = symbol
* index = trading_day

```{r}
tr_data <- readr::read_csv("/Users/ania/Desktop/FTSE_Prices.csv")
tr_data <- tr_data %>% 
           as_tsibble(key = symbol, index = 'trading_day') %>% 
           fill(close, .direction="downup") # Interpolate missing values

tr_data
```

### **1.1 Create a time-plot of your data and briefly describe it (max 75 words)** (1 points)

```{r}
tr_data %>%
  autoplot() +
  scale_x_continuous()
```

------

There is a growth trend with some recessions after first 20 trading days, then right before trading day 600. The magnitude of growth is changing, with the most rapid increase after around 170 trading day.

------

### **2. Create two training datasets containing 80, 60 of your data** (1 points)

Call them `train_1` and `train_2`.

```{r}
n_obs80 <-as.integer(nrow(tr_data)*0.8)
n_obs60 <- as.integer(nrow(tr_data)*0.6)
train_1 <- 
  tr_data %>%
  slice(1:n_obs80)
train_1


train_2 <- 
  tr_data %>%
  slice(1:n_obs60)
train_2

```

### **3. Fit the following models to each of the training datasets:** (1 points)

* a Naïve model (`naive`).
* a Simple Exponential Smoothing model. Call it `ses_tr`
* a Trended Exponential Smoothing model with and additive dampled trend and no seasonality. Call it `holts_damped`

```{r}
# YOUR CODE GOES HERE, DO NOT CREATE ADDITIONAL CODE SNIPPETS
fit_tr1 <- 
  train_1 %>% 
  model(
    naive_tr1 = NAIVE(close),
    ses_tr1 =  ETS(close~error("A")+ trend("N")+season("N")),
    holts_damped_tr1 = ETS(close~error("A")+ trend("Ad")+season("N"))
  )

fit_tr2 <- 
  train_2 %>% 
  model(
    naive_tr2 = NAIVE(close),
    ses_tr2 =  ETS(close~error("A")+ trend("N")+season("N")),
    holts_damped_tr2 = ETS(close~error("A")+ trend("Ad")+season("N"))
  )

# Bind all the models in a single mable to handle forecasts more easily.
fit <- bind_cols(
  fit_tr1 %>% select(-symbol), # Exclude column symbol to be able to bind columns
  fit_tr2 %>% select(-symbol)
)

fit
```

### **4. Generate forecasts of 10 trading days for each of the trained models** (1 point)

The result of this step should be a `fable` or forecast table. Name it `fc`

Add a column `h` to `fc` indicating the forecast horizon of each forecast.

* After adding that column, apply the following command: `as_fable(response = "close", distribution = close)`. This is to ensure that the output after performing these operations is still a `fable`, which can be used in combination with the function `accuracy()`

```{r}
fc <- 
  fit %>%
  forecast(h=10)
fc <- 
  fc %>%
  group_by(.model) %>%
  mutate(h = row_number()) %>%
  ungroup() %>%
  as_fable(response = 'close', distribution = close) %>%
  select(h, everything())
fc
```

### **5. For each combination of model, training dataset and forecast horizon compute the RMSE, MAE and MAPE. Store the result in a variable called `summary`** (1 point)


```{r}
summary <-
  fc %>%
  accuracy(tr_data, by = c(".model", "h")) %>%
  select(h, .model, MAE, RMSE, MAPE) %>%
  arrange(RMSE)
summary
```

```{r}
# 
```


### **6. Produce the following graphs and answer the questions** (2.5 points) 

Using `facet_wrap` produce a graph for the RMSE and another one for the MAPE for each forecast 

The graphs should depict the RMSE for each forecast horizon and for each combination of model and training dataset.


```{r}
# changing the dataset changes
summary %>%
  ggplot(aes(x = h, y = RMSE, color = .model)) + # Coerce h to factor
  geom_point() +
  geom_line(alpha = 0.25) +
  facet_wrap(~ metric, nrow = 2, scales = "free") + 
  scale_x_continuous(
    breaks = seq(1, max(summary$h))
  )
# in slice we still have test and training sets, but what we do is we make it stay the same
# the problem with this is that when we look at the ggplot graph the errors don't naturally increase as h increases and also when we change between models it doesn't change much, however when we change dataset it changes the error and it shouldn't be like that
```

Then answer these questions:

* Does the training dataset have an effect on the errors?

------

**YOUR ANSWER GOES HERE**
MAX 30 WORDS

------

* Does one of the models outperform the other?

------

**YOUR ANSWER GOES HERE**
MAX 30 WORDS

------

### **7. Evaluate the same metrics on the same models, but this time using cross validation** (2.5 points)

The end-goal is that you produce the same final graph (facet_wrap graph on the error metrics), but this time only three lines per graph should be depicted (one line per model).

The smallest training dataset shall contain 60% of the trading days. The trading datasets shall increase in steps of 2 trading days.

```{r}
# YOUR CODE GOES HERE
# YOUR ANSWER GOES HERE
```

* What is the difference between these graphs and the ones we generated before? Answer briefly below.

------

YOUR ANSWER GOES HERE: MAX 30 WORDS

------

* Does one of the models outperform the others?

------

YOUR ANSWER GOES HERE: MAX 30 WORDS

------

### **8. Reflect on the results and present some conclusions** (0 points)

------

YOUR ANSWER GOES HERE.
MAX 100 WORDS.

------
